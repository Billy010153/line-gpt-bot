import os
import threading
from flask import Flask, request, jsonify
from openai import OpenAI
import requests

app = Flask(__name__)

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
LINE_ACCESS_TOKEN = os.environ.get("LINE_ACCESS_TOKEN")
LINE_REPLY_URL = "https://api.line.me/v2/bot/message/reply"

conversation_histories = {}
MAX_HISTORY = 5
PREFERRED_MODEL = "gpt-4-turbo"
FALLBACK_MODEL = "gpt-3.5-turbo"

def load_user_profile():
    try:
        with open("user_profile.txt", "r", encoding="utf-8") as f:
            lines = [line.strip() for line in f if line.strip() and not line.startswith("#")]
            return "\n".join(lines)
    except Exception as e:
        print("è¼‰å…¥å€‹äººè³‡æ–™å¤±æ•—ï¼š", str(e))
        return ""

USER_PROFILE = load_user_profile()

def process_event(event):
    try:
        if event["type"] == "message" and event["message"]["type"] == "text":
            user_message = event["message"]["text"]
            reply_token = event.get("replyToken")
            user_id = event.get("source", {}).get("userId", "anonymous")

            if not reply_token:
                print("âŒ ç„¡æ•ˆçš„ replyToken")
                return

            system_prompt = f"""ä½ æ˜¯ä¸€ä½å«ã€Œè‡ªæ¨‚ã€çš„å°ç£äººï¼Œè«‹æŠŠç”¨æˆ¶ç•¶ä½œå¥½æœ‹å‹ï¼Œä»¥ç°¡å–®æ˜ç­ä¸”è¼•é¬†å¹½é»˜çš„èªæ°£å›ç­”ï¼Œä»¥ä¸‹æ˜¯ä½ çš„çœŸå¯¦èƒŒæ™¯è³‡æ–™ï¼š

{USER_PROFILE}
"""

            if user_id not in conversation_histories:
                conversation_histories[user_id] = [
                    {"role": "system", "content": system_prompt}
                ]

            history = conversation_histories[user_id]
            history.append({"role": "user", "content": user_message})

            try:
                response = client.chat.completions.create(
                    model=PREFERRED_MODEL,
                    messages=history
                )
            except Exception as e:
                print("âš ï¸ GPT-4-Turbo ç™¼ç”ŸéŒ¯èª¤ï¼Œé™ç´šè‡³ GPT-3.5ï¼š", e)
                response = client.chat.completions.create(
                    model=FALLBACK_MODEL,
                    messages=history
                )

            reply_message = response.choices[0].message.content.strip()
            history.append({"role": "assistant", "content": reply_message})
            if len(history) > MAX_HISTORY + 1:
                conversation_histories[user_id] = history[-(MAX_HISTORY + 1):]

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {LINE_ACCESS_TOKEN}"
            }
            payload = {
                "replyToken": reply_token,
                "messages": [{"type": "text", "text": reply_message}]
            }
            r = requests.post(LINE_REPLY_URL, headers=headers, json=payload)
            print("ğŸ“¤ å‚³é€è‡³ LINE ç‹€æ…‹ï¼š", r.status_code)

    except Exception as e:
        print("âŒ éŒ¯èª¤ï¼š", str(e))

@app.route("/callback", methods=["POST"])
def callback():
    body = request.get_json()
    print("ğŸ“© æ”¶åˆ° LINE Webhook:", body)
    if "events" in body:
        for event in body["events"]:
            threading.Thread(target=process_event, args=(event,)).start()
    return jsonify({"status": "ok"})

@app.route("/")
def index():
    return "æˆ‘æ˜¯æœ¬äºº LINE Botï¼ˆæ”¯æ´è‡ªå‹•é™ç´šæ¨¡å‹ï¼‰å·²å•Ÿå‹•ï¼"

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
