import os
import threading
from flask import Flask, request, jsonify
from openai import OpenAI
import requests

app = Flask(__name__)

# åˆå§‹åŒ– OpenAI clientï¼Œå¾ç’°å¢ƒè®Šæ•¸è®€å–é‡‘é‘°
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
LINE_ACCESS_TOKEN = os.environ.get("LINE_ACCESS_TOKEN")
LINE_REPLY_URL = "https://api.line.me/v2/bot/message/reply"

# å…¨åŸŸè¨˜æ†¶å­—å…¸ï¼šä»¥ä½¿ç”¨è€… ID ç‚º keyï¼Œå„²å­˜å°è©±æ­·å²ï¼ˆåˆ—è¡¨ï¼‰
conversation_histories = {}
MAX_HISTORY = 5  # å¯èª¿æ•´ä¿ç•™æœ€è¿‘å¹¾å‰‡å°è©±

def load_user_profile():
    """
    è¼‰å…¥å€‹äººè³‡æ–™ï¼Œä½œç‚ºç³»çµ±æç¤ºçš„ä¸€éƒ¨ä»½ã€‚
    """
    try:
        with open("user_profile.txt", "r", encoding="utf-8") as f:
            lines = [line.strip() for line in f if line.strip() and not line.startswith("#")]
            return "\n".join(lines)
    except Exception as e:
        print("è¼‰å…¥å€‹äººè³‡æ–™å¤±æ•—ï¼š", str(e))
        return ""

USER_PROFILE = load_user_profile()

def process_event(event):
    try:
        if event["type"] == "message" and event["message"]["type"] == "text":
            user_message = event["message"]["text"]
            reply_token = event.get("replyToken")
            if not reply_token:
                print("âŒ ç„¡æ•ˆçš„ replyToken")
                return

            # å–å¾—ä½¿ç”¨è€… IDï¼Œè‹¥ç„¡å‰‡ç”¨ "anonymous"
            user_id = event.get("source", {}).get("userId", "anonymous")
            print(f"âœ… æ”¶åˆ° {user_id} çš„è¨Šæ¯ï¼š{user_message}")

            # æº–å‚™ç³»çµ±æç¤ºï¼šå°‡ä½ çš„å€‹äººè³‡æ–™èˆ‡è§’è‰²èªªæ˜å‚³çµ¦ GPT
            system_prompt = f"""ä½ æ˜¯ä¸€ä½å«ã€Œè‡ªæ¨‚ã€çš„å°ç£äººï¼Œè«‹æŠŠç”¨æˆ¶ç•¶ä½œå¥½æœ‹å‹ï¼Œä»¥ç°¡å–®æ˜ç­ä¸”è¼•é¬†å¹½é»˜çš„èªæ°£å›ç­”ï¼Œä»¥ä¸‹æ˜¯ä½ çš„çœŸå¯¦èƒŒæ™¯è³‡æ–™ï¼š
{USER_PROFILE}

è«‹æ ¹æ“šä»¥ä¸Šè³‡è¨Šï¼Œç”¨ç¬¬ä¸€äººç¨±ä¸”è¦ªåˆ‡è‡ªç„¶åœ°å›ç­”å•é¡Œã€‚"""

            # å–å¾—è©²ä½¿ç”¨è€…çš„å°è©±æ­·å²ï¼Œè‹¥ç„¡å‰‡åˆå§‹åŒ–
            if user_id not in conversation_histories:
                conversation_histories[user_id] = [
                    {"role": "system", "content": system_prompt}
                ]
            history = conversation_histories[user_id]

            # å°‡æœ€æ–°çš„ä½¿ç”¨è€…è¨Šæ¯åŠ å…¥å°è©±æ­·å²
            history.append({"role": "user", "content": user_message})

            # å‘¼å« OpenAI API å–å¾—å›æ‡‰
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=history
            )
            reply_message = response.choices[0].message.content.strip()

            # å°‡ AI å›è¦†ä¹ŸåŠ å…¥å°è©±æ­·å²
            history.append({"role": "assistant", "content": reply_message})
            # ä¿ç•™æœ€æ–° MAX_HISTORY æ¢å°è©±ï¼ˆåŒ…å« system promptï¼‰
            if len(history) > MAX_HISTORY + 1:  # +1 å› ç‚ºç¬¬ä¸€ç­†æ˜¯ system prompt
                conversation_histories[user_id] = history[-(MAX_HISTORY + 1):]

            print(f"ğŸ’¬ å›è¦†çµ¦ {user_id}ï¼š{reply_message}")

            # ç™¼é€å›è¦†çµ¦ LINE
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {LINE_ACCESS_TOKEN}"
            }
            payload = {
                "replyToken": reply_token,
                "messages": [{"type": "text", "text": reply_message}]
            }
            r = requests.post(LINE_REPLY_URL, headers=headers, json=payload)
            print("ğŸ“¤ å‚³é€è‡³ LINE ç‹€æ…‹ï¼š", r.status_code)
    except Exception as e:
        print("âŒ éŒ¯èª¤ï¼š", str(e))

@app.route("/callback", methods=["POST"])
def callback():
    body = request.get_json()
    print("ğŸ“© æ”¶åˆ° LINE Webhook:", body)
    if "events" in body:
        for event in body["events"]:
            threading.Thread(target=process_event, args=(event,)).start()
    return jsonify({"status": "ok"})

@app.route("/")
def index():
    return "æˆ‘æ˜¯æœ¬äºº LINE Bot å·²ä¸Šç·šï¼"

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
